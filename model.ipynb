{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import data_processing as dp\n",
    "import json\n",
    "\n",
    "import t2g\n",
    "# import g2t\n",
    "import g2t_copy as g2t\n",
    "\n",
    "# # instantiate models\n",
    "# g2t_model = SimpleT5()\n",
    "# t2g_model = t2g.T2GModel()\n",
    "\n",
    "# # load (supports t5, mt5, byT5 models)\n",
    "# g2t_model.from_pretrained(\"t5\",\"t5-base\")\n",
    "\n",
    "\n",
    "#create dataloader\n",
    "#t, g = dp.create_cycle_dataloader(vocab, batch_size = 8, shuffle=True)\n",
    "\n",
    "\n",
    "class CycleModel():\n",
    "\tdef __init__(self, vocab, device = \"cpu\"):\n",
    "\t\tif device == \"gpu\":\n",
    "\t\t\tself.device = torch.device('cuda:0')\n",
    "\t\telse:\n",
    "\t\t\tself.device = torch.device('cpu')\n",
    "\n",
    "\t\tself.t2g_model = t2g.T2GModel(vocab, self.device, 768)\n",
    "\t\tself.g2t_model = g2t.G2TModel(vocab)\n",
    "\t\tself.t2g_opt = torch.optim.Adam(self.t2g_model.model.parameters())\n",
    "\t\tself.g2t_opt = torch.optim.Adam(self.g2t_model.t5_model.parameters())\n",
    "\t\tself.vocab = vocab\n",
    "    \n",
    "\tdef t_cycle(self, text_batch): # optimizes g2t\n",
    "\t\tself.t2g_model.eval()\n",
    "\t\tself.g2t_model.train()\n",
    "\n",
    "\t\tgold_text = self.g2t_model.g2t_preprocess(text_batch, mode=\"TGT\")\n",
    "\t\t# gold_text = gold_text.to(self.device) # bs x gold_text_len\n",
    "\t\t# bs, gold_text_len = gold_text.shape\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tpred_graphs = self.t2g_model.predict(text_batch) #synthetic batch of graphs\n",
    "\t\t\n",
    "\t\tself.g2t_opt.zero_grad()\n",
    "\n",
    "\t\t# #tokenize pred_graphs\n",
    "\t\tpred_graphs, ents, raw_ents = self.g2t_model.g2t_preprocess(pred_graphs, mode=\"G2T\")\n",
    "\t\tpred_graphs_ids = self.g2t_model.tokenizer(pred_graphs, return_tensors='pt', truncation=True, padding=True).input_ids\n",
    "\t\tgold_text_ids = self.g2t_model.tokenizer(gold_text, return_tensors='pt', truncation=True, padding=True).input_ids\n",
    "\t\tloss = self.g2t_model.t5_model(input_ids = pred_graphs_ids, labels = gold_text_ids).loss\n",
    "\t\tloss.backward()\n",
    "\t\tself.g2t_opt.step()\n",
    "\t\treturn loss.item()\n",
    "\n",
    "\n",
    "\tdef g_cycle(self, graph_batch): # optimizes t2g\n",
    "\t\t\"\"\"\n",
    "\t\t\tInput: graph_batch: list (length batch_size) of dicts with entities and relations\n",
    "\n",
    "\t\t\tPerforms G2T then optimizes T2G by computing loss of generated graph and original (gold) graph\n",
    "\t\t\"\"\"\n",
    "\t\tself.g2t_model.eval()\n",
    "\t\tself.t2g_model.train()\n",
    "\t\tmax_ents = max([len(graph[\"entities\"]) for graph in graph_batch])\n",
    "\t\tgold_graphs = [dp.relation2Indices(self.vocab, graph, max_ents) for graph in graph_batch]\n",
    "\t\tgold_graphs = torch.stack(gold_graphs)\n",
    "\t\tgold_graphs = gold_graphs.to(self.device) # bs x max_ents x max_ents - used for loss computation\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tpred_text = self.g2t_model.predict(graph_batch)\n",
    "\t\t\n",
    "\t\t#print(pred_text[0])\n",
    "\n",
    "\t\tprint(\"pred text\", pred_text)\n",
    "\n",
    "\t\tself.t2g_opt.zero_grad()\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tpred_text, pred_text_ents = self.t2g_model.t2g_preprocess(pred_text)\n",
    "\t\t\n",
    "\n",
    "\t\tgraph_log_probs = self.t2g_model.model.forward(pred_text.to(self.device), pred_text_ents.to(self.device)) # bs x max_ents x max_ents x num_relations - log probs of each relation between all entities in each batch\n",
    "\t\tprint(\"gold shape\", gold_graphs.shape)\n",
    "\t\tprint(\"log probs shape\", graph_log_probs.shape)\n",
    "\t\tprint(gold_graphs)\n",
    "\t\tprint()\n",
    "\t\tprint(graph_log_probs)\n",
    "\t\tloss = F.nll_loss(graph_log_probs.view(-1, graph_log_probs.shape[-1]), gold_graphs.view(-1), ignore_index=self.vocab.relations.word2idx['<EMPTY>']) # ignore index should be 0\n",
    "\t\tloss.backward()\n",
    "\t\t#nn.utils.clip_grad_norm_(g2t_model.parameters(), config['clip'])\n",
    "\t\tself.t2g_opt.step()\n",
    "\t\treturn loss.item()\n",
    "\n",
    "\tdef back_translation(self, text_batch, graph_batch):\n",
    "\t\tg_loss = self.g_cycle(graph_batch)\n",
    "\t\tt_loss = self.t_cycle(text_batch)\n",
    "\t\treturn g_loss, t_loss\n",
    "\n",
    "\tdef train(self, epochs, batch_size, learning_rate, shuffle):\n",
    "\t\t\n",
    "\t\tfor i in range(epochs):\n",
    "\t\t\t\n",
    "\t\t\ttcycle_dataloader, gcycle_dataloader = dp.create_cycle_dataloader(raw_json_file=self.vocab.raw_data, batch_size = batch_size, shuffle=shuffle)\n",
    "\t\t\tdataloader = list(zip(tcycle_dataloader, gcycle_dataloader))\n",
    "\t\t\tfor index, (tbatch, gbatch) in tqdm.tqdm(enumerate(dataloader)):\n",
    "\t\t\t\t# if index != 7:\n",
    "\t\t\t\t# \tbreak\n",
    "\t\t\t\tg_loss, t_loss = self.back_translation(tbatch, gbatch)\n",
    "\t\t\t\tprint(\"g cycle loss: \", g_loss)\n",
    "\t\t\t\tprint(\"t cycle loss: \" , t_loss)\n",
    "                    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Creating empty vocabulary object\nFinished Parsing Text\n"
    }
   ],
   "source": [
    "# Opening JSON file\n",
    "f = open('json_datasets/train.json', 'r')\n",
    "\n",
    "raw_train = json.load(f)\n",
    "\n",
    "vocab = dp.Vocabulary()\n",
    "vocab.parseText(raw_train)\n",
    "\n",
    "#create cycle\n",
    "\n",
    "cycle_model = CycleModel(vocab)\n",
    "tcycle_dataloader, gcycle_dataloader = dp.create_cycle_dataloader(vocab.raw_data, batch_size = 8, shuffle=False)\n",
    "\n",
    "tbatch = tcycle_dataloader[0]\n",
    "gbatch = gcycle_dataloader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[{'relations': [[['Aarhus', 'Airport'], 'cityServed', ['``', 'Aarhus', ',', 'Denmark', \"''\"]]], 'text': 'the <ENT_1> of <ENT_0> .', 'entities': [['``', 'Aarhus', ',', 'Denmark', \"''\"], ['Aarhus', 'Airport']]}\n {'relations': [[['Aarhus', 'Airport'], 'cityServed', ['``', 'Aarhus', ',', 'Denmark', \"''\"]]], 'text': '<ENT_1> serves the city of <ENT_0> .', 'entities': [['``', 'Aarhus', ',', 'Denmark', \"''\"], ['Aarhus', 'Airport']]}\n {'relations': [[['Aarhus', 'Airport'], 'cityServed', ['Aarhus']]], 'text': '<ENT_1> serves the city of <ENT_0> .', 'entities': [['Aarhus'], ['Aarhus', 'Airport']]}\n {'relations': [[['Aarhus', 'Airport'], 'elevationAboveTheSeaLevel_(in_metres)', ['25.0']]], 'text': '<ENT_0> is <ENT_1> metres above sea level .', 'entities': [['Aarhus', 'Airport'], ['25.0']]}\n {'relations': [[['Aarhus', 'Airport'], 'elevationAboveTheSeaLevel_(in_metres)', ['25.0']]], 'text': '<ENT_0> is at an elevation of <ENT_1> metres above seal level .', 'entities': [['Aarhus', 'Airport'], ['25.0']]}\n {'relations': [[['Aarhus', 'Airport'], 'elevationAboveTheSeaLevel_(in_metres)', ['25.0']]], 'text': '<ENT_0> is <ENT_1> metres above the sea level .', 'entities': [['Aarhus', 'Airport'], ['25.0']]}\n {'relations': [[['Aarhus', 'Airport'], 'location', ['Tirstrup']]], 'text': '<ENT_0> is located in <ENT_1> .', 'entities': [['Aarhus', 'Airport'], ['Tirstrup']]}\n {'relations': [[['Aarhus', 'Airport'], 'location', ['Tirstrup']]], 'text': 'the location of <ENT_0> is <ENT_1> .', 'entities': [['Aarhus', 'Airport'], ['Tirstrup']]}]\n"
    }
   ],
   "source": [
    "print(tbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['the Aarhus Airport of Aarhus , Denmark .', 'Aarhus Airport serves the city of Aarhus , Denmark .', 'Aarhus Airport serves the city of Aarhus .', 'Aarhus Airport is 25.0 metres above sea level .', 'Aarhus Airport is at an elevation of 25.0 metres above seal level .', 'Aarhus Airport is 25.0 metres above the sea level .', 'Aarhus Airport is located in Tirstrup .', 'the location of Aarhus Airport is Tirstrup .']\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.2224383354187012"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "cycle_model.t_cycle(tbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<g2t_copy.G2TModel at 0x1039517f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cycle_model.g2t_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "7.856348514556885"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "cycle_model.g_cycle(gbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[{'text': 'g2 <ENT_0> <ENT_1> <ENT_2>', 'entities': [['1928'], ['737'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': 'g2 <ENT_0> <ENT_1> <ENT_2>', 'entities': [['1928'], ['737'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': '<ENT_1> <ENT_0> <ENT_2>', 'entities': [['1928'], ['European', 'University', 'Association'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': '<ENT_1> <ENT_0> <ENT_2>', 'entities': [['1928'], ['European', 'University', 'Association'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': '<ENT_1> <ENT_0> <ENT_2>', 'entities': [['1928'], ['European', 'University', 'Association'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': '<ENT_1> University School of Business and Social Sciences at the <ENT_1> University. <ENT_0> <ENT_2>', 'entities': [['Magistrate'], ['Aarhus'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': '<ENT_1> University School of Business and Social Sciences at the <ENT_1> University. <ENT_0> <ENT_2>', 'entities': [['Magistrate'], ['Aarhus'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': '<ENT_1> University School of Business and Social Sciences at the <ENT_1> University. <ENT_0> <ENT_2>', 'entities': [['Magistrate'], ['Aarhus'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}]\ntensor([[   2,    1, 5830, 6252, 4570, 3995, 4571, 4112, 5828, 5829, 4365, 4242,\n         3912, 4364,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0],\n        [   2,    1, 5830, 6252, 4570, 3995, 4571, 4112, 5828, 5829, 4365, 4242,\n         3912, 4364,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0],\n        [   2, 4651, 4364, 5531, 5830, 4570, 3995, 4571, 4112, 5828, 5829, 4365,\n         4242, 3912, 4364,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n            0],\n        [   2, 4651, 4364, 5531, 5830, 4570, 3995, 4571, 4112, 5828, 5829, 4365,\n         4242, 3912, 4364,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n            0],\n        [   2, 4651, 4364, 5531, 5830, 4570, 3995, 4571, 4112, 5828, 5829, 4365,\n         4242, 3912, 4364,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n            0],\n        [   2, 3912,  721,  999,   12, 1000,  313, 2598, 2599,   34,   10, 3912,\n            1, 5777, 4570, 3995, 4571, 4112, 5828, 5829, 4365, 4242, 3912, 4364,\n            3],\n        [   2, 3912,  721,  999,   12, 1000,  313, 2598, 2599,   34,   10, 3912,\n            1, 5777, 4570, 3995, 4571, 4112, 5828, 5829, 4365, 4242, 3912, 4364,\n            3],\n        [   2, 3912,  721,  999,   12, 1000,  313, 2598, 2599,   34,   10, 3912,\n            1, 5777, 4570, 3995, 4571, 4112, 5828, 5829, 4365, 4242, 3912, 4364,\n            3]])\ntensor([[[ 2,  3],\n         [ 3,  4],\n         [ 4, 14],\n         [-1, -1]],\n\n        [[ 2,  3],\n         [ 3,  4],\n         [ 4, 14],\n         [-1, -1]],\n\n        [[ 1,  4],\n         [ 4,  5],\n         [ 5, 15],\n         [-1, -1]],\n\n        [[ 1,  4],\n         [ 4,  5],\n         [ 5, 15],\n         [-1, -1]],\n\n        [[ 1,  4],\n         [ 4,  5],\n         [ 5, 15],\n         [-1, -1]],\n\n        [[ 1,  2],\n         [11, 12],\n         [13, 14],\n         [14, 24]],\n\n        [[ 1,  2],\n         [11, 12],\n         [13, 14],\n         [14, 24]],\n\n        [[ 1,  2],\n         [11, 12],\n         [13, 14],\n         [14, 24]]])\n"
    }
   ],
   "source": [
    "pred_text = [{'text': 'g2 <ENT_0> <ENT_1> <ENT_2>', 'entities': [['1928'], ['737'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': 'g2 <ENT_0> <ENT_1> <ENT_2>', 'entities': [['1928'], ['737'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': '<ENT_1> <ENT_0> <ENT_2>', 'entities': [['1928'], ['European', 'University', 'Association'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': '<ENT_1> <ENT_0> <ENT_2>', 'entities': [['1928'], ['European', 'University', 'Association'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': '<ENT_1> <ENT_0> <ENT_2>', 'entities': [['1928'], ['European', 'University', 'Association'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': '<ENT_1> University School of Business and Social Sciences at the <ENT_1> University. <ENT_0> <ENT_2>', 'entities': [['Magistrate'], ['Aarhus'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': '<ENT_1> University School of Business and Social Sciences at the <ENT_1> University. <ENT_0> <ENT_2>', 'entities': [['Magistrate'], ['Aarhus'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': '<ENT_1> University School of Business and Social Sciences at the <ENT_1> University. <ENT_0> <ENT_2>', 'entities': [['Magistrate'], ['Aarhus'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}]\n",
    "print(pred_text)\n",
    "pred_text, pred_text_ents = cycle_model.t2g_model.t2g_preprocess(pred_text)\n",
    "print(pred_text)\n",
    "print(pred_text_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "0it [00:00, ?it/s]pred text [{'text': 'H> <ENT_2> R> ethnic Group T> <ENT_0> <ENT_1>', 'entities': [['Germans', 'of', 'Romania'], ['1', 'Decembrie', '1918', 'University'], ['Romania']]}, {'text': 'H> <ENT_2> R> ethnic Group T> <ENT_0> <ENT_1>', 'entities': [['Germans', 'of', 'Romania'], ['1', 'Decembrie', '1918', 'University'], ['Romania']]}, {'text': ': H> <ENT_2> R> leader Name T> <ENT_1> <ENT_0>', 'entities': [['1', 'Decembrie', '1918', 'University'], ['Klaus', 'Iohannis'], ['Romania']]}, {'text': 'H> <ENT_2> R> patron Saint T> <ENT_1> <ENT_0>', 'entities': [['1', 'Decembrie', '1918', 'University'], ['Andrew', 'the', 'Apostle'], ['Romania']]}, {'text': 'H> <ENT_2> R> patron Saint T> <ENT_1> <ENT_0>', 'entities': [['1', 'Decembrie', '1918', 'University'], ['Andrew', 'the', 'Apostle'], ['Romania']]}, {'text': 'g2t: H> School of Business and Social Sciences at the Aar <ENT_0> <ENT_1> <ENT_2>', 'entities': [['Denmark'], ['737'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': 'g2t: H> School of Business and Social Sciences at the Aar <ENT_0> <ENT_1> <ENT_2>', 'entities': [['Denmark'], ['737'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': 'H> <ENT_2> R <ENT_0> <ENT_1>', 'entities': [['1928'], ['737'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}]\ngold shape torch.Size([8, 3, 3])\nlog probs shape torch.Size([8, 3, 3, 249])\ntensor([[[  4,   4,   4],\n         [  4,   4,  11],\n         [112,   4,   4]],\n\n        [[  4,   4,   4],\n         [  4,   4,  11],\n         [112,   4,   4]],\n\n        [[  4,   4,  11],\n         [  4,   4,   4],\n         [  4,  23,   4]],\n\n        [[  4,   4,  11],\n         [  4,   4,   4],\n         [  4, 242,   4]],\n\n        [[  4,   4,  11],\n         [  4,   4,   4],\n         [  4, 242,   4]],\n\n        [[  4,   4,   4],\n         [  4,   4,   4],\n         [ 11, 186,   4]],\n\n        [[  4,   4,   4],\n         [  4,   4,   4],\n         [ 11, 186,   4]],\n\n        [[  4,   4,   4],\n         [  4,   4,   4],\n         [156, 186,   4]]])\n\ntensor([[[[-13.5046,  -9.7640,  -5.4484,  ...,  -5.8584,  -8.0489,  -8.2592],\n          [ -6.6413, -11.2417,  -9.8457,  ...,  -8.3572,  -7.2220,  -7.4931],\n          [-11.0378, -13.0765,  -4.1995,  ...,  -5.7342,  -8.6976,  -5.5421]],\n\n         [[-11.2575,  -6.6079,  -7.4519,  ..., -10.1648,  -8.8923,  -9.0685],\n          [ -9.8063,  -8.8613,  -7.5089,  ...,  -8.2305,  -5.2920,  -9.1932],\n          [ -9.4129,  -8.6820,  -7.5452,  ...,  -9.5331,  -4.4142,  -7.9654]],\n\n         [[-11.2136,  -6.5175,  -7.5055,  ..., -10.2974,  -7.2807,  -7.0598],\n          [ -6.9927,  -9.4132,  -9.3831,  ...,  -8.6503,  -6.8660, -10.2096],\n          [ -9.0271,  -9.8637,  -8.8364,  ..., -11.6405,  -7.9218,  -9.9303]]],\n\n\n        [[[-11.7441, -11.4953,  -9.8374,  ...,  -6.2304,  -7.5546, -10.6693],\n          [ -9.0500,  -7.7303,  -5.7345,  ...,  -9.5238,  -6.5005,  -7.5105],\n          [ -8.4831,  -6.5467,  -6.3272,  ...,  -8.4841,  -7.2742,  -9.5076]],\n\n         [[-11.9251,  -8.3720,  -5.6485,  ...,  -9.3004,  -9.6857,  -5.8420],\n          [-10.7354,  -9.9573,  -8.7780,  ...,  -9.1094,  -7.6082,  -9.1537],\n          [ -5.6372,  -8.7057,  -5.2404,  ...,  -8.0792,  -7.2671,  -9.0305]],\n\n         [[-10.4262, -11.3356,  -6.1851,  ..., -11.3902,  -6.2449,  -6.3706],\n          [ -8.0392,  -8.0295, -10.7283,  ...,  -7.1412,  -8.3340,  -9.5168],\n          [-10.4208, -11.9474,  -4.3646,  ...,  -9.2700,  -6.6533,  -9.6504]]],\n\n\n        [[[-11.0320,  -5.9153,  -5.3851,  ...,  -8.5715,  -7.6039,  -6.9467],\n          [-10.6986,  -4.9436,  -7.5247,  ..., -10.5193,  -8.5809,  -3.4846],\n          [-12.1091,  -9.7673,  -5.7893,  ...,  -7.5064,  -5.1684,  -6.0484]],\n\n         [[-11.2767,  -6.5154,  -6.3779,  ...,  -7.1198, -13.7884,  -4.8469],\n          [-11.4618,  -6.7570,  -9.9287,  ..., -10.2483,  -9.4907,  -9.6155],\n          [-11.3480,  -6.1162,  -2.8840,  ...,  -8.0827,  -3.5682, -10.9821]],\n\n         [[ -9.8021, -10.4586, -10.0252,  ...,  -9.1859,  -6.4200, -10.1398],\n          [ -8.6138,  -7.3135,  -5.3609,  ...,  -8.3555, -11.0934,  -7.2712],\n          [-11.3951, -10.8166,  -7.7462,  ..., -11.4707,  -7.2237,  -9.2301]]],\n\n\n        ...,\n\n\n        [[[ -6.9862,  -5.0029,  -5.2911,  ...,  -7.8523,  -9.9919,  -8.5828],\n          [ -7.8512,  -6.7247,  -4.4176,  ..., -11.7581,  -5.4161,  -6.7892],\n          [ -8.5433,  -5.6769,  -4.6794,  ...,  -8.1685,  -5.5923,  -8.4511]],\n\n         [[-10.3392,  -6.9954,  -6.3234,  ..., -10.4519,  -3.2788,  -8.2169],\n          [ -9.7671,  -9.9291,  -3.2230,  ..., -11.4374,  -3.8527,  -5.1072],\n          [ -8.3712, -12.2082,  -5.7830,  ...,  -9.1912,  -7.4923,  -7.3576]],\n\n         [[ -7.8108,  -5.9831,  -6.3623,  ..., -12.2891,  -5.3482,  -9.1608],\n          [ -7.1455,  -9.8049,  -7.4247,  ..., -13.1277,  -8.6380,  -7.8881],\n          [ -5.0358,  -8.7242,  -2.4120,  ...,  -5.0671,  -5.4316,  -7.2752]]],\n\n\n        [[[ -8.2854,  -6.7597,  -3.3656,  ..., -11.9176,  -7.0073,  -6.7712],\n          [ -7.5898, -11.2751,  -7.3079,  ...,  -9.7621,  -3.8604,  -5.3203],\n          [ -5.7754,  -9.3980,  -5.3860,  ...,  -8.3019,  -5.9604,  -6.6727]],\n\n         [[-10.2835,  -6.9955,  -4.8195,  ..., -10.0145,  -6.9827, -11.8828],\n          [ -5.6095,  -6.6656,  -5.3059,  ..., -10.1965,  -5.9221,  -5.1969],\n          [-12.8568,  -6.8676,  -5.7318,  ...,  -5.4981,  -2.7676,  -5.8242]],\n\n         [[ -9.1247,  -8.1112,  -6.4851,  ..., -11.9069,  -7.2282,  -9.6294],\n          [ -6.4013, -10.9941,  -4.5871,  ..., -10.8380,  -6.2875,  -6.9646],\n          [ -3.4582,  -9.2530,  -6.3178,  ...,  -6.6828,  -5.1070,  -9.5033]]],\n\n\n        [[[ -5.3991, -10.8814,  -6.9110,  ...,  -7.7652,  -8.7420,  -5.1384],\n          [-11.9401, -13.2407,  -4.6470,  ...,  -8.4040, -12.0300,  -8.1801],\n          [-11.9121,  -5.6845,  -6.3958,  ...,  -6.3797, -11.9834,  -6.8471]],\n\n         [[ -4.6739, -10.6020,  -7.7169,  ...,  -6.0256,  -6.6109,  -9.0031],\n          [-11.8620,  -5.3947,  -5.0699,  ..., -10.4102,  -8.9505,  -8.3654],\n          [ -6.9862, -10.6682,  -8.3421,  ..., -12.8284,  -9.1127,  -5.8812]],\n\n         [[ -8.7297, -11.0157,  -8.6026,  ...,  -7.8647,  -4.8965,  -5.3209],\n          [ -6.3986,  -7.6532,  -9.1814,  ...,  -7.7710,  -7.9124,  -5.1306],\n          [ -5.6383,  -6.9928, -11.7881,  ..., -15.0362,  -7.0307,  -6.4313]]]],\n       grad_fn=<LogSoftmaxBackward>)\n1it [00:18, 18.24s/it]g cycle loss:  8.216432571411133\nt cycle loss:  4.355376720428467\n1it [00:24, 24.14s/it]pred text [{'text': 'g2 <ENT_0> <ENT_1> <ENT_2>', 'entities': [['1928'], ['737'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': 'g2 <ENT_0> <ENT_1> <ENT_2>', 'entities': [['1928'], ['737'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': '<ENT_1> <ENT_0> <ENT_2>', 'entities': [['1928'], ['European', 'University', 'Association'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': '<ENT_1> <ENT_0> <ENT_2>', 'entities': [['1928'], ['European', 'University', 'Association'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': '<ENT_1> <ENT_0> <ENT_2>', 'entities': [['1928'], ['European', 'University', 'Association'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': '<ENT_1> University School of Business and Social Sciences at the <ENT_1> University. <ENT_0> <ENT_2>', 'entities': [['Magistrate'], ['Aarhus'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': '<ENT_1> University School of Business and Social Sciences at the <ENT_1> University. <ENT_0> <ENT_2>', 'entities': [['Magistrate'], ['Aarhus'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}, {'text': '<ENT_1> University School of Business and Social Sciences at the <ENT_1> University. <ENT_0> <ENT_2>', 'entities': [['Magistrate'], ['Aarhus'], ['School', 'of', 'Business', 'and', 'Social', 'Sciences', 'at', 'the', 'Aarhus', 'University']]}]\ngold shape torch.Size([8, 3, 3])\nlog probs shape torch.Size([8, 4, 4, 249])\ntensor([[[  4,   4,   4],\n         [  4,   4,   4],\n         [156, 186,   4]],\n\n        [[  4,   4,   4],\n         [  4,   4,   4],\n         [156, 186,   4]],\n\n        [[  4,   4,   4],\n         [  4,   4,   4],\n         [156,  82,   4]],\n\n        [[  4,   4,   4],\n         [  4,   4,   4],\n         [156,  82,   4]],\n\n        [[  4,   4,   4],\n         [  4,   4,   4],\n         [156,  82,   4]],\n\n        [[  4,   4,   4],\n         [110,   4,   4],\n         [  4, 183,   4]],\n\n        [[  4,   4,   4],\n         [110,   4,   4],\n         [  4, 183,   4]],\n\n        [[  4,   4,   4],\n         [110,   4,   4],\n         [  4, 183,   4]]])\n\ntensor([[[[-57.1273, -53.0960, -58.8653,  ..., -53.6678, -52.2601, -57.7062],\n          [-53.7588, -44.4575, -58.4600,  ..., -48.0366, -48.2366, -55.7537],\n          [-46.9064, -46.8124, -48.3561,  ..., -47.8820, -48.3741, -51.6942],\n          [ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175]],\n\n         [[-60.3857, -55.4483, -58.6960,  ..., -60.0114, -56.2849, -61.6632],\n          [-50.7889, -46.5588, -54.0373,  ..., -51.6346, -50.2113, -56.0125],\n          [-55.8590, -50.9101, -58.5443,  ..., -55.0045, -48.1138, -57.0863],\n          [ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175]],\n\n         [[-47.5032, -46.5516, -47.6578,  ..., -48.0551, -43.0977, -49.0066],\n          [-41.6850, -38.0042, -44.7410,  ..., -40.6409, -38.3053, -42.7415],\n          [-50.9239, -50.1615, -49.9386,  ..., -49.0982, -47.9182, -51.0699],\n          [ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175]],\n\n         [[ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175],\n          [ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175],\n          [ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175],\n          [ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175]]],\n\n\n        [[[-51.1942, -43.8179, -54.2286,  ..., -50.2802, -50.6150, -52.3128],\n          [-61.8555, -51.9753, -59.3157,  ..., -59.5883, -52.5688, -61.5321],\n          [-61.0414, -54.6623, -58.1423,  ..., -54.8220, -52.8005, -57.7095],\n          [ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175]],\n\n         [[-50.1279, -49.2263, -54.3887,  ..., -56.9721, -45.0949, -52.6127],\n          [-52.5728, -50.0221, -52.0733,  ..., -51.7913, -47.0271, -52.0440],\n          [-62.8584, -56.9648, -64.9158,  ..., -61.8522, -55.7530, -63.9364],\n          [ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175]],\n\n         [[-50.9690, -40.7966, -47.0923,  ..., -43.7172, -45.5120, -50.5464],\n          [-48.3891, -46.0561, -49.3824,  ..., -49.2989, -44.3170, -47.2117],\n          [-43.5125, -41.4343, -41.9649,  ..., -38.8470, -39.3938, -44.1080],\n          [ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175]],\n\n         [[ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175],\n          [ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175],\n          [ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175],\n          [ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175]]],\n\n\n        [[[-33.0862, -36.4656, -36.1297,  ..., -33.8258, -31.5001, -37.4865],\n          [-34.5153, -28.1933, -38.3968,  ..., -29.0820, -31.5216, -34.6068],\n          [-44.4102, -36.7901, -43.0625,  ..., -44.0459, -41.8182, -43.1262],\n          [ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175]],\n\n         [[-31.7133, -31.5724, -36.6755,  ..., -34.9032, -34.9303, -39.8919],\n          [-36.5749, -34.6081, -36.6832,  ..., -29.5755, -34.0902, -40.0608],\n          [-37.5046, -34.2868, -41.0265,  ..., -37.5665, -34.7824, -42.6242],\n          [ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175]],\n\n         [[-34.8089, -32.6220, -34.0624,  ..., -32.7614, -34.6509, -34.7445],\n          [-38.4147, -32.5538, -37.1974,  ..., -35.6125, -31.6584, -39.7410],\n          [-44.5454, -46.5450, -48.3851,  ..., -46.4984, -45.4634, -52.1251],\n          [ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175]],\n\n         [[ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175],\n          [ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175],\n          [ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175],\n          [ -5.5175,  -5.5175,  -5.5175,  ...,  -5.5175,  -5.5175,  -5.5175]]],\n\n\n        ...,\n\n\n        [[[-26.3347, -20.5654, -24.1316,  ..., -19.2160, -18.2846, -19.3886],\n          [-35.6615, -24.5137, -34.2190,  ..., -31.2995, -27.6851, -32.4524],\n          [-37.3719, -31.1652, -38.1943,  ..., -35.5943, -30.9330, -33.8720],\n          [-35.8209, -32.0119, -35.5079,  ..., -27.7229, -29.0561, -32.5135]],\n\n         [[-34.4709, -29.8463, -29.5812,  ..., -31.2381, -26.5012, -30.5422],\n          [-56.5145, -46.2660, -50.2213,  ..., -50.4081, -43.7269, -47.0463],\n          [-47.0207, -38.6245, -48.3881,  ..., -43.9505, -37.2678, -44.3674],\n          [-39.9343, -39.3629, -45.1125,  ..., -41.0577, -36.3974, -45.1914]],\n\n         [[-49.5415, -37.5695, -42.9678,  ..., -40.3028, -34.7780, -43.9404],\n          [-58.1585, -54.1393, -54.5201,  ..., -54.8757, -50.7291, -56.2214],\n          [-52.5592, -44.5521, -49.6991,  ..., -49.2767, -45.4629, -51.9048],\n          [-45.9289, -43.3856, -50.2412,  ..., -45.7191, -43.0020, -51.1567]],\n\n         [[-37.2835, -32.2536, -35.6696,  ..., -35.5225, -27.5289, -36.2160],\n          [-48.5321, -42.5876, -46.6473,  ..., -44.8134, -40.3406, -47.6531],\n          [-41.0382, -33.9915, -33.4471,  ..., -36.5311, -35.9232, -38.4066],\n          [-43.0125, -38.4880, -45.7898,  ..., -43.5585, -41.6144, -42.1425]]],\n\n\n        [[[-30.7201, -25.4683, -33.3486,  ..., -29.2557, -20.4420, -24.0000],\n          [-40.5902, -35.2130, -41.0740,  ..., -36.9923, -35.5544, -39.2561],\n          [-41.4990, -36.1820, -44.1258,  ..., -37.6963, -37.6305, -40.5457],\n          [-32.7248, -31.9096, -35.4279,  ..., -34.2957, -32.8594, -33.5511]],\n\n         [[-45.4614, -33.8622, -43.3856,  ..., -39.2294, -33.1200, -39.6791],\n          [-50.3844, -42.4034, -48.9607,  ..., -47.0117, -39.3137, -43.8214],\n          [-48.9135, -38.6838, -48.1273,  ..., -47.1464, -40.2470, -43.6225],\n          [-50.2949, -45.7577, -50.4049,  ..., -45.0456, -40.4204, -48.1003]],\n\n         [[-41.7281, -37.0304, -40.3532,  ..., -36.2565, -29.4480, -35.8767],\n          [-51.3279, -47.3747, -51.1201,  ..., -49.4019, -48.3000, -48.2390],\n          [-59.8933, -51.8750, -55.8158,  ..., -55.3271, -51.2513, -58.1315],\n          [-56.0487, -54.5920, -58.1659,  ..., -55.3693, -50.4679, -53.7533]],\n\n         [[-39.7995, -31.4466, -35.3024,  ..., -33.5900, -31.0035, -29.7017],\n          [-45.8802, -39.9657, -43.3608,  ..., -43.1946, -41.1178, -47.2192],\n          [-41.6611, -40.7210, -46.1323,  ..., -42.6933, -40.6246, -44.8750],\n          [-43.6877, -41.8855, -44.4548,  ..., -36.6136, -36.9085, -41.4622]]],\n\n\n        [[[-29.8591, -22.2169, -32.6671,  ..., -26.5906, -21.1298, -23.6424],\n          [-45.0145, -35.4880, -40.3339,  ..., -39.0747, -32.7561, -40.4247],\n          [-38.8174, -28.4132, -37.9167,  ..., -37.3355, -32.3080, -35.6793],\n          [-41.3051, -35.7169, -43.5637,  ..., -36.5151, -35.6458, -43.3522]],\n\n         [[-31.7221, -26.5273, -32.2228,  ..., -29.6599, -23.4656, -29.2524],\n          [-51.6922, -47.2780, -51.9549,  ..., -50.3031, -47.8331, -47.5126],\n          [-48.7192, -41.0018, -47.4495,  ..., -46.3729, -38.8263, -48.1650],\n          [-44.9328, -35.9779, -44.6156,  ..., -40.4672, -38.8577, -43.3606]],\n\n         [[-43.9562, -39.2436, -45.2174,  ..., -39.0954, -35.8680, -38.6137],\n          [-53.2747, -49.3832, -52.9515,  ..., -49.2201, -43.3596, -49.8962],\n          [-48.0424, -35.6966, -47.6872,  ..., -45.2242, -35.8911, -44.3118],\n          [-55.9895, -51.7925, -52.8018,  ..., -46.7960, -45.0362, -56.7298]],\n\n         [[-39.3067, -31.6850, -35.5506,  ..., -34.0682, -33.0015, -34.3130],\n          [-47.5721, -44.2365, -45.7178,  ..., -40.8573, -42.0269, -45.4318],\n          [-44.7630, -43.7387, -43.0518,  ..., -47.5045, -41.5009, -50.3570],\n          [-48.6734, -44.9445, -51.8047,  ..., -48.8620, -49.1085, -51.6303]]]],\n       grad_fn=<LogSoftmaxBackward>)\n\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Expected input batch_size (128) to match target batch_size (72).",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2v/tg9q212n2_x1mz9848phgdgr0000gn/T/ipykernel_21313/868124277.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcycle_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/2v/tg9q212n2_x1mz9848phgdgr0000gn/T/ipykernel_21313/2371336017.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, learning_rate, shuffle)\u001b[0m\n\u001b[1;32m    117\u001b[0m                                 \u001b[0;31m# if index != 7:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                                 \u001b[0;31m#       break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                                 \u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mback_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"g cycle loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t cycle loss: \"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mt_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2v/tg9q212n2_x1mz9848phgdgr0000gn/T/ipykernel_21313/2371336017.py\u001b[0m in \u001b[0;36mback_translation\u001b[0;34m(self, text_batch, graph_batch)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mback_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0mt_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2v/tg9q212n2_x1mz9848phgdgr0000gn/T/ipykernel_21313/2371336017.py\u001b[0m in \u001b[0;36mg_cycle\u001b[0;34m(self, graph_batch)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_log_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_log_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_log_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_graphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<EMPTY>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ignore index should be 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;31m#nn.utils.clip_grad_norm_(g2t_model.parameters(), config['clip'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2260\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2261\u001b[0;31m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[0m\u001b[1;32m   2262\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   2263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (128) to match target batch_size (72)."
     ]
    }
   ],
   "source": [
    "cycle_model.train(epochs=1, batch_size = 8, learning_rate = 0.1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'relations': [[['Aarhus', 'Airport'], 'cityServed', ['``', 'Aarhus', ',', 'Denmark', \"''\"]]], 'text': 'the <ENT_1> of <ENT_0> .', 'entities': [['``', 'Aarhus', ',', 'Denmark', \"''\"], ['Aarhus', 'Airport']]}\n",
      " {'relations': [[['Aarhus', 'Airport'], 'cityServed', ['``', 'Aarhus', ',', 'Denmark', \"''\"]]], 'text': '<ENT_1> serves the city of <ENT_0> .', 'entities': [['``', 'Aarhus', ',', 'Denmark', \"''\"], ['Aarhus', 'Airport']]}\n",
      " {'relations': [[['Aarhus', 'Airport'], 'cityServed', ['Aarhus']]], 'text': '<ENT_1> serves the city of <ENT_0> .', 'entities': [['Aarhus'], ['Aarhus', 'Airport']]}\n",
      " {'relations': [[['Aarhus', 'Airport'], 'elevationAboveTheSeaLevel_(in_metres)', ['25.0']]], 'text': '<ENT_0> is <ENT_1> metres above sea level .', 'entities': [['Aarhus', 'Airport'], ['25.0']]}\n",
      " {'relations': [[['Aarhus', 'Airport'], 'elevationAboveTheSeaLevel_(in_metres)', ['25.0']]], 'text': '<ENT_0> is at an elevation of <ENT_1> metres above seal level .', 'entities': [['Aarhus', 'Airport'], ['25.0']]}\n",
      " {'relations': [[['Aarhus', 'Airport'], 'elevationAboveTheSeaLevel_(in_metres)', ['25.0']]], 'text': '<ENT_0> is <ENT_1> metres above the sea level .', 'entities': [['Aarhus', 'Airport'], ['25.0']]}\n",
      " {'relations': [[['Aarhus', 'Airport'], 'location', ['Tirstrup']]], 'text': '<ENT_0> is located in <ENT_1> .', 'entities': [['Aarhus', 'Airport'], ['Tirstrup']]}\n",
      " {'relations': [[['Aarhus', 'Airport'], 'location', ['Tirstrup']]], 'text': 'the location of <ENT_0> is <ENT_1> .', 'entities': [['Aarhus', 'Airport'], ['Tirstrup']]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataloader = list(zip(tcycle_dataloader, gcycle_dataloader))\n",
    "for index, (tbatch, gbatch) in tqdm.tqdm(enumerate(diataloader)):\n",
    "\tprint(tbatch)\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c5ce5b9604fc8445e4e5f27c24807def7cbbefbcd7dbec7e9c2f61ff534743b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python38564bitbaseconda53d3aa08a74d40a8860ef501a21f2398"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}