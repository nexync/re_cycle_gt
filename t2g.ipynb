{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import tqdm\n",
    "\n",
    "class ModelLSTM(nn.Module):\n",
    "\tdef __init__(self, input_types, relation_types, model_dim, dropout = 0.5):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.word_types = input_types\n",
    "\t\tself.relation_types = relation_types\n",
    "\t\tself.dropout = dropout\n",
    "\t\tself.model_dim = model_dim\n",
    "\n",
    "\t\tself.emb = nn.Embedding(input_types, self.model_dim)\n",
    "\t\tself.lstm = nn.LSTM(self.model_dim, self.model_dim//2, batch_first=True, bidirectional=True, num_layers=2)\n",
    "\t\tself.relation_layer1 = nn.Linear(self.model_dim , self.model_dim)\n",
    "\t\tself.relation_layer2 = nn.Linear(self.model_dim , self.model_dim)\n",
    "\t\tself.drop = nn.Dropout(self.dropout)\n",
    "\t\tself.projection = nn.Linear(self.model_dim , self.model_dim)\n",
    "\t\tself.decoder = nn.Linear(self.model_dim , self.relation_types)\n",
    "\t\tself.layer_norm = nn.LayerNorm(self.model_dim)\n",
    "\n",
    "\t\tself.init_params()\n",
    "\n",
    "\tdef init_params(self):\n",
    "\t\tnn.init.xavier_normal_(self.relation_layer1.weight.data)\n",
    "\t\tnn.init.xavier_normal_(self.relation_layer2.weight.data)\n",
    "\t\tnn.init.xavier_normal_(self.projection.weight.data)\n",
    "\t\tnn.init.xavier_normal_(self.decoder.weight.data)\n",
    "\n",
    "\t\tnn.init.constant_(self.relation_layer1.bias.data , 0)\n",
    "\t\tnn.init.constant_(self.relation_layer2.bias.data , 0)\n",
    "\t\tnn.init.constant_(self.projection.bias.data , 0)\n",
    "\t\tnn.init.constant_(self.decoder.bias.data , 0)\n",
    "\n",
    "\t#def forward(self, batch):\n",
    "\tdef forward(self, sents, ent_inds):\n",
    "\t\t#sents = batch['text']\n",
    "\t\tsents, (c_0, h_0) = self.lstm(self.emb(sents))\n",
    "\n",
    "\t\tbs, _, hidden_dim = sents.shape\n",
    "\t\t\n",
    "\t\tmax_ents = max([max([ent_ind[0] for ent_ind in batch_ent_inds])] for batch_ent_inds in ent_inds)\n",
    "\t\t\n",
    "\t\tcont_word_mask = sents.new_zeros(bs, max_ents)\n",
    "\t\tcont_word_embs = sents.new_zeros(bs, max_ents, hidden_dim)\n",
    "\n",
    "\t\t#for b, (sent,entind) in enumerate(zip(sents,batch['entity_inds'])):\n",
    "\t\tfor b, (sent,entind) in enumerate(zip(sents, ent_inds)):\n",
    "\t\t\tfor z in entind:\n",
    "\t\t\t\tif z[0] == -1:\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\twordemb = sent[z[1]:z[2]]\n",
    "\t\t\t\t\tmean_emb = torch.mean(wordemb, dim = 0)\n",
    "\t\t\t\t\tcont_word_embs[b, z[0]] = (cont_word_mask[b, z[0]]*cont_word_embs[b, z[0]] + mean_emb)/(cont_word_mask[b, z[0]] + 1)\n",
    "\t\t\t\t\tcont_word_mask[b, z[0]] += 1\n",
    "\t\t\t# for n_ent, wordemb in enumerate([sent[z[0]:z[1]] for z in entind]):\n",
    "\t\t\t# \tcont_word_embs[b, n_ent] = torch.mean(wordemb, dim = 0)\n",
    "\t\t\t# \tcont_word_mask[b, n_ent] = 1\n",
    "\n",
    "\t\t# bs x max_ents x model_dim\n",
    "\t\tcont_word_embs = self.layer_norm(cont_word_embs)\n",
    "\t\tcont_word_mask = torch.clamp(cont_word_mask, 0, 1)\n",
    "\n",
    "\t\trel1 = self.relation_layer1(cont_word_embs)\n",
    "\t\trel2 = self.relation_layer2(cont_word_embs)\n",
    "\n",
    "\t\t#bs x max_ents x max_ents x model_dim\n",
    "\t\tout = rel1.unsqueeze(1) + rel2.unsqueeze(2)\n",
    "\n",
    "\t\tout = self.drop(out)\n",
    "\t\tout = self.projection(out)\n",
    "\t\tout = self.decoder(out)\n",
    "\n",
    "\t\tout = out * cont_word_mask.view(bs,max_ents,1,1) * cont_word_mask.view(bs,1,max_ents,1)\n",
    "\n",
    "\t\treturn torch.log_softmax(out, -1) # bs x max ents x max_ents x num_relations\n",
    "\n",
    "class T2GModel():\n",
    "\tdef __init__(self, vocab, device, model_dim):\n",
    "\t\tself.inp_types = len(vocab.entities.wordlist) + len(vocab.text.wordlist)\n",
    "\t\tself.rel_types = len(vocab.relations.wordlist)\n",
    "\n",
    "\t\tself.model = ModelLSTM(self.inp_types, self.rel_types, model_dim = model_dim).to(device)\n",
    "\t\tself.vocab = vocab\n",
    "\t\tself.device = device\n",
    "\n",
    "\tdef eval(self):\n",
    "\t\tself.model.eval()\n",
    "    \n",
    "\tdef train(self):\n",
    "\t\tself.model.train()\n",
    "\tdef t2g_preprocess(self, batch):\n",
    "\t\t\t\"\"\" \n",
    "\t\t\t\tinput: list of dictionaries in raw_json_format\n",
    "\t\t\t\toutput: prepreprocessed dictionaries containing text, entity inds\n",
    "\t\t\t\"\"\"\n",
    "\n",
    "\t\t\tdef entity2Indices(entity, mode = \"T2G\"):\n",
    "\t\t\t\ttemp = torch.zeros(len(entity), dtype = torch.long)\n",
    "\t\t\t\tfor ind, word in enumerate(entity):\n",
    "\t\t\t\t\tif word not in self.vocab.entities.word2idx:\n",
    "\t\t\t\t\t\ttemp[ind] = self.vocab.entities.word2idx[\"<UNK>\"]\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\ttemp[ind] = self.vocab.entities.word2idx[word]\n",
    "\t\t\t\treturn temp\n",
    "\t\t\t\t\t\n",
    "\t\t\tdef text2Indices(text):\n",
    "\t\t\t\ttemp = torch.zeros(len(text.split()) + 2, dtype=torch.long)\n",
    "\t\t\t\ttemp[0] = self.vocab.text.word2idx[\"<SOS>\"]\n",
    "\t\t\t\tfor ind, word in enumerate(text.split()):\n",
    "\t\t\t\t\tif word not in self.vocab.text.word2idx:\n",
    "\t\t\t\t\t\ttemp[ind + 1] = self.vocab.text.word2idx[\"<UNK>\"]\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\ttemp[ind + 1] = self.vocab.text.word2idx[word]\n",
    "\t\t\t\ttemp[-1] = self.vocab.text.word2idx[\"<EOS>\"]\n",
    "\t\t\t\treturn temp\n",
    "\t\t\t\n",
    "\n",
    "\n",
    "\t\t\tdef concatTextEntities(raw_json_sentence):\n",
    "\t\t\t\tsent = text2Indices(raw_json_sentence['text'])\n",
    "\t\t\t\tmodified_input = torch.LongTensor([0])\n",
    "\t\t\t\tlbound = 0\n",
    "\t\t\t\tentity_locations = []\n",
    "\t\t\t\tadditional_words = 0\n",
    "\t\t\t\tfor index, value in enumerate(sent):\n",
    "\t\t\t\t\tif value.item() in self.vocab.entityindices:\n",
    "\t\t\t\t\t\ttemp = entity2Indices(raw_json_sentence['entities'][self.vocab.entityindices[value.item()]])\n",
    "\t\t\t\t\t\ttemp += len(self.vocab.text.wordlist)\n",
    "\t\t\t\t\t\tmodified_input = torch.cat((modified_input, sent[lbound:index], temp), dim = 0)\n",
    "\t\t\t\t\t\tentity_locations.append([self.vocab.entityindices[value.item()], index + additional_words, index + additional_words + len(temp)])\n",
    "\t\t\t\t\t\tadditional_words += len(temp) - 1\n",
    "\t\t\t\t\t\tlbound = index + 1\n",
    "\t\t\t\tmodified_input = torch.cat((modified_input, sent[lbound:]), dim = 0)[1:]\n",
    "\t\t\t\treturn modified_input, torch.LongTensor(entity_locations)\n",
    "\n",
    "\t\t\tmaxlentext = 0\n",
    "\t\t\tmaxents = 0\n",
    "\t\t\ttemp_text = []\n",
    "\t\t\ttemp_inds = []\n",
    "\t\t\tfor raw_json_sentence in batch:\n",
    "\t\t\t\t(text, entity_inds) = concatTextEntities(raw_json_sentence)\n",
    "\t\t\t\ttemp_inds.append(entity_inds)\n",
    "\t\t\t\tif len(entity_inds) > maxents:\n",
    "\t\t\t\t\tmaxents = len(entity_inds)\n",
    "\t\t\t\ttemp_text.append(text)\n",
    "\t\t\t\tif text.shape[0] > maxlentext:\n",
    "\t\t\t\t\tmaxlentext = text.shape[0]\n",
    "\t\t\t\t\n",
    "\t\t\tfinal_text = torch.ones((len(batch), maxlentext), dtype = torch.long)*self.vocab.text.word2idx[\"<EMPTY>\"]\n",
    "\t\t\tfinal_ents = torch.ones((len(batch), maxents, 3), dtype = torch.long)*-1\n",
    "\n",
    "\t\t\tfor k in range(len(batch)):\n",
    "\t\t\t\tfinal_text[k][:len(temp_text[k])] = temp_text[k]\n",
    "\t\t\t\tfinal_ents[k][:len(temp_inds[k])] = temp_inds[k]\n",
    "\t\t\t\n",
    "\t\t\treturn final_text, final_ents\n",
    "\n",
    "\t# input - texts with original entities taken out (list of dicts with text and entities)\n",
    "\t# output - batch of graphs (list of dicts with relations and entities)\n",
    "\tdef predict(self, batch):\n",
    "\t\tpreprocessed_text, preprocessed_inds = self.t2g_preprocess(batch)\n",
    "\n",
    "\t\tpreds = self.model(preprocessed_text.to(self.device), preprocessed_inds.to(self.device))\n",
    "\t\tpreds = torch.argmax(preds, -1)\n",
    "\n",
    "\t\tbs, ne, _ = preds.shape\n",
    "\n",
    "\t\toutput = [] #list of dictionaries\n",
    "\n",
    "\t\tfor b in range(bs):\n",
    "\t\t\ttemp = {\n",
    "\t\t\t\t\"relations\": [],\n",
    "\t\t\t\t\"entities\": batch[b]['entities']\n",
    "\t\t\t}\n",
    "\t\t\tfor i in range(0, ne):\n",
    "\t\t\t\tfor j in range(i+1, ne):\n",
    "\t\t\t\t\ttemp['relations'].append([temp['entities'][i], self.vocab.relations.wordlist[preds[b, i, j]], temp['entities'][j]])\n",
    "\t\t\toutput.append(temp)\n",
    "\t\treturn output\n",
    "\t\n",
    "\t\n",
    "\n",
    "# def train_model_supervised(model, num_relations, dataloader, learning_rate = 1e10, epochs = 30):\n",
    "# \t\"\"\"\n",
    "# \t\"\"\"\n",
    "\n",
    "# \t# Create model\n",
    "# \toptimzer = torch.optim.Adam(model.model.parameters())\n",
    "# \tcriterion = nn.NLLLoss()\n",
    "\n",
    "# \t#state_dict_clone = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "# \tfor t in range(epochs):\n",
    "# \t\tloss_this_epoch = 0.0\n",
    "# \t\tfor batch in tqdm.tqdm(range(len(dataloader))):\n",
    "    \n",
    "# \t\t\tlog_probs = model(dataloader[batch])\n",
    "# \t\t\tlabels = dataloader[batch]['labels']\t\n",
    "\n",
    "# \t\t\tloss = criterion(log_probs.view(-1, num_relations), labels.view(-1))\n",
    "# \t\t\tloss_this_epoch += loss.item()\n",
    "# \t\t\toptimzer.zero_grad()\n",
    "# \t\t\tloss.backward()\n",
    "# \t\t\t# torch.nn.utils.clip_grad_norm_(\n",
    "# \t\t\t#     [p for group in optimzer.param_groups for p in group['params']], CLIP)\n",
    "# \t\t\toptimzer.step()\n",
    "\n",
    "# \t\t# \t# load best parameters\n",
    "# \t\t# curr_state_dict = encdec_model.state_dict()\n",
    "# \t\t# for key in state_dict_clone.keys():\n",
    "# \t\t# \tcurr_state_dict[key].copy_(state_dict_clone[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating empty vocabulary object\n",
      "Finished Parsing Text\n"
     ]
    }
   ],
   "source": [
    "# importing the module\n",
    "import json\n",
    "\n",
    "import data_processing as dp\n",
    "  \n",
    "# Opening JSON file\n",
    "f = open('json_datasets/train.json', 'r')\n",
    "\n",
    "raw_train = json.load(f)\n",
    "\n",
    "vocab = dp.Vocabulary()\n",
    "vocab.parseText(raw_train)\n",
    "\n",
    "t, g = dp.create_cycle_dataloader(raw_train, 8, False)\n",
    "dataloader = t+g\n",
    "\n",
    "inp_types = len(vocab.entities.wordlist) + len(vocab.text.wordlist)\n",
    "rel_types = len(vocab.relations.wordlist)\n",
    "\n",
    "t2g_model = T2GModel(vocab, torch.device('cpu'), 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_supervised(model, num_relations, dataloader, learning_rate = 1e10, epochs = 30):\n",
    "\t\"\"\"\n",
    "\t\"\"\"\n",
    "\n",
    "\t# Create model\n",
    "\toptimzer = torch.optim.Adam(model.model.parameters())\n",
    "\tcriterion = nn.NLLLoss()\n",
    "\n",
    "\t#state_dict_clone = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "\tfor t in range(epochs):\n",
    "\t\tloss_this_epoch = 0.0\n",
    "\t\tfor batch in tqdm.tqdm(dataloader):\n",
    "\t\t\tpre_text, pre_ents = model.t2g_preprocess(batch)\n",
    "\n",
    "\t\t\tbs, _ = pre_text.shape\n",
    "\n",
    "\t\t\tmax_ents = max([len(ex['entities']) for ex in t[0]])\n",
    "\n",
    "\t\t\tlabels = torch.zeros((bs, max_ents, max_ents), dtype = torch.long)\n",
    "\t\t\tfor k, raw_json in enumerate(batch):\n",
    "\t\t\t\tlabels[k] = dp.relation2Indices(vocab, raw_json, max_ents)\n",
    "    \n",
    "\t\t\tlog_probs = model(pre_text, pre_ents)\n",
    "\n",
    "\t\t\tloss = criterion(log_probs.view(-1, num_relations), labels.view(-1))\n",
    "\t\t\tloss_this_epoch += loss.item()\n",
    "\t\t\toptimzer.zero_grad()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\t# torch.nn.utils.clip_grad_norm_(\n",
    "\t\t\t#     [p for group in optimzer.param_groups for p in group['params']], CLIP)\n",
    "\t\t\toptimzer.step()\n",
    "\n",
    "\t\t# \t# load best parameters\n",
    "\t\t# curr_state_dict = encdec_model.state_dict()\n",
    "\t\t# for key in state_dict_clone.keys():\n",
    "\t\t# \tcurr_state_dict[key].copy_(state_dict_clone[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1630 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30584/2247481946.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_model_supervised\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt2g_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrel_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30584/1558334110.py\u001b[0m in \u001b[0;36mtrain_model_supervised\u001b[1;34m(model, num_relations, dataloader, learning_rate, epochs)\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[0mloss_this_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                         \u001b[0mpre_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_ents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt2g_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                         \u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpre_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30584/1366515608.py\u001b[0m in \u001b[0;36mt2g_preprocess\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    146\u001b[0m                         \u001b[0mtemp_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                         \u001b[0mtemp_inds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m                         \u001b[1;32mfor\u001b[0m \u001b[0mraw_json_sentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m                                 \u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentity_inds\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcatTextEntities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_json_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m                                 \u001b[0mtemp_inds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity_inds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "train_model_supervised(t2g_model, rel_types, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_inds': [[(2, 4), (5, 10)],\n",
       "   [(1, 3), (7, 12)],\n",
       "   [(1, 3), (7, 8)],\n",
       "   [(1, 3), (4, 5)],\n",
       "   [(1, 3), (8, 9)],\n",
       "   [(1, 3), (4, 5)],\n",
       "   [(1, 3), (6, 7)],\n",
       "   [(4, 6), (7, 8)]],\n",
       "  'text_lengths': [12, 14, 10, 11, 15, 12, 9, 10],\n",
       "  'entity_lengths': [2, 2, 2, 2, 2, 2, 2, 2],\n",
       "  'text': tensor([[   2,   10, 3912, 3916,   12, 3911, 3912, 3913, 3914, 3915,   14,    3,\n",
       "              0,    0,    0],\n",
       "          [   2, 3912, 3916,   21,   10,    8,   12, 3911, 3912, 3913, 3914, 3915,\n",
       "             14,    3,    0],\n",
       "          [   2, 3912, 3916,   21,   10,    8,   12, 3912,   14,    3,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   2, 3912, 3916,   29, 3917,   28,   30,   31,   32,   14,    3,    0,\n",
       "              0,    0,    0],\n",
       "          [   2, 3912, 3916,   29,   34,   35,   22,   12, 3917,   28,   30,   36,\n",
       "             32,   14,    3],\n",
       "          [   2, 3912, 3916,   29, 3917,   28,   30,   10,   31,   32,   14,    3,\n",
       "              0,    0,    0],\n",
       "          [   2, 3912, 3916,   29,   38,   27, 3918,   14,    3,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   2,   10,   37,   12, 3912, 3916,   29, 3918,   14,    3,    0,    0,\n",
       "              0,    0,    0]]),\n",
       "  'labels': tensor([[[4, 4],\n",
       "           [5, 4]],\n",
       "  \n",
       "          [[4, 4],\n",
       "           [5, 4]],\n",
       "  \n",
       "          [[4, 4],\n",
       "           [5, 4]],\n",
       "  \n",
       "          [[4, 6],\n",
       "           [4, 4]],\n",
       "  \n",
       "          [[4, 6],\n",
       "           [4, 4]],\n",
       "  \n",
       "          [[4, 6],\n",
       "           [4, 4]],\n",
       "  \n",
       "          [[4, 7],\n",
       "           [4, 4]],\n",
       "  \n",
       "          [[4, 7],\n",
       "           [4, 4]]])},\n",
       " {'entity_inds': [[(1, 3), (6, 11)],\n",
       "   [(1, 6), (11, 13)],\n",
       "   [(1, 2), (7, 9)],\n",
       "   [(1, 2), (3, 5)],\n",
       "   [(1, 3), (7, 8)],\n",
       "   [(1, 3), (6, 7)],\n",
       "   [(1, 3), (8, 9)],\n",
       "   [(7, 9), (10, 11)]],\n",
       "  'text_lengths': [13, 15, 11, 7, 11, 9, 11, 13],\n",
       "  'entity_lengths': [2, 2, 2, 2, 2, 2, 2, 2],\n",
       "  'text': tensor([[   2, 3912, 3916,   29,   42,   43, 3911, 3912, 3919, 3920, 3915,   14,\n",
       "              3,    0,    0],\n",
       "          [   2, 3911, 3912, 3919, 3920, 3915,   29,   10,   46,   47,   12, 3912,\n",
       "           3916,   14,    3],\n",
       "          [   2, 3921,   29,   10,   40,   47,   48, 3912, 3916,   14,    3,    0,\n",
       "              0,    0,    0],\n",
       "          [   2, 3921,   50, 3912, 3916,   14,    3,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   2, 3912, 3916,   29,   42,   43,   10, 3921,   47,   14,    3,    0,\n",
       "              0,    0,    0],\n",
       "          [   2, 3912, 3916,   51,   53,   29, 3922,   14,    3,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   2, 3912, 3916,   55,   56,   51,   53,   12, 3922,   14,    3,    0,\n",
       "              0,    0,    0],\n",
       "          [   2,   10,   53,   12,   10,   51,   34, 3912, 3916,   29, 3922,   14,\n",
       "              3,    0,    0]]),\n",
       "  'labels': tensor([[[4, 4],\n",
       "           [8, 4]],\n",
       "  \n",
       "          [[4, 4],\n",
       "           [8, 4]],\n",
       "  \n",
       "          [[4, 4],\n",
       "           [8, 4]],\n",
       "  \n",
       "          [[4, 4],\n",
       "           [8, 4]],\n",
       "  \n",
       "          [[4, 4],\n",
       "           [8, 4]],\n",
       "  \n",
       "          [[4, 4],\n",
       "           [9, 4]],\n",
       "  \n",
       "          [[4, 4],\n",
       "           [9, 4]],\n",
       "  \n",
       "          [[4, 4],\n",
       "           [9, 4]]])},\n",
       " {'entity_inds': [[(5, 7), (8, 9)],\n",
       "   [(5, 7), (8, 9)],\n",
       "   [(1, 3), (6, 9)],\n",
       "   [(1, 4), (10, 12)],\n",
       "   [(5, 7), (8, 11)],\n",
       "   [(5, 7), (9, 12)],\n",
       "   [(1, 4), (9, 11)],\n",
       "   [(5, 7), (8, 11)]],\n",
       "  'text_lengths': [12, 11, 11, 14, 13, 15, 14, 13],\n",
       "  'entity_lengths': [2, 2, 2, 2, 2, 2, 2, 2],\n",
       "  'text': tensor([[   2,   10,   51,   53,   34, 3912, 3916,   29, 3923,   57,   14,    3,\n",
       "              0,    0,    0],\n",
       "          [   2,   10,   51,   53,   34, 3912, 3916,   29, 3923,   14,    3,    0,\n",
       "              0,    0,    0],\n",
       "          [   2, 3912, 3916,   51,   60,   29, 3911, 3924, 3915,   14,    3,    0,\n",
       "              0,    0,    0],\n",
       "          [   2, 3911, 3924, 3915,   29,   10,   51,   60,   12,   10, 3912, 3916,\n",
       "             14,    3,    0],\n",
       "          [   2,   10,   51,   60,   12, 3912, 3916,   29, 3911, 3924, 3915,   14,\n",
       "              3,    0,    0],\n",
       "          [   2,   10,   51,   60,   34, 3912, 3916,   29,   15, 3911, 3925, 3915,\n",
       "             15,   14,    3],\n",
       "          [   2, 3911, 3925, 3915,   29,   10,   51,   60,   34, 3912, 3916,   17,\n",
       "             14,    3,    0],\n",
       "          [   2,   10,   51,   60,   12, 3912, 3916,   29, 3911, 3925, 3915,   14,\n",
       "              3,    0,    0]]),\n",
       "  'labels': tensor([[[ 4,  4],\n",
       "           [ 9,  4]],\n",
       "  \n",
       "          [[ 4,  4],\n",
       "           [ 9,  4]],\n",
       "  \n",
       "          [[ 4,  4],\n",
       "           [10,  4]],\n",
       "  \n",
       "          [[ 4,  4],\n",
       "           [10,  4]],\n",
       "  \n",
       "          [[ 4,  4],\n",
       "           [10,  4]],\n",
       "  \n",
       "          [[ 4, 10],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4, 10],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4, 10],\n",
       "           [ 4,  4]]])},\n",
       " {'entity_inds': [[(1, 4), (7, 9)],\n",
       "   [(1, 4), (7, 9)],\n",
       "   [(1, 4), (8, 10)],\n",
       "   [(1, 4), (7, 11)],\n",
       "   [(1, 4), (6, 10)],\n",
       "   [(1, 4), (7, 11)],\n",
       "   [(1, 4), (7, 11)],\n",
       "   [(1, 4), (7, 11)]],\n",
       "  'text_lengths': [11, 11, 12, 13, 12, 13, 13, 13],\n",
       "  'entity_lengths': [2, 2, 2, 2, 2, 2, 2, 2],\n",
       "  'text': tensor([[   2, 3926, 3913, 3927,   29,   27,   10, 3928, 3929,   14,    3,    0,\n",
       "              0],\n",
       "          [   2, 3926, 3913, 3927,   29,   27,   10, 3928, 3929,   14,    3,    0,\n",
       "              0],\n",
       "          [   2, 3926, 3913, 3927,   29,   38,   27,   10, 3928, 3929,   14,    3,\n",
       "              0],\n",
       "          [   2, 3926, 3913, 3927,   29,   70,   12, 3930, 3931, 3913, 3927,   14,\n",
       "              3],\n",
       "          [   2, 3926, 3913, 3927,   70,   12, 3930, 3931, 3913, 3927,   14,    3,\n",
       "              0],\n",
       "          [   2, 3926, 3913, 3927,   29,   70,   12, 3932, 3931, 3913, 3927,   14,\n",
       "              3],\n",
       "          [   2, 3926, 3913, 3927,   56,   70,   12, 3932, 3931, 3913, 3927,   14,\n",
       "              3],\n",
       "          [   2, 3926, 3913, 3927,   29,   70,   12, 3932, 3931, 3913, 3927,   14,\n",
       "              3]]),\n",
       "  'labels': tensor([[[ 4, 11],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4, 11],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4, 11],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4, 12],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4, 12],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4, 12],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4, 12],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4, 12],\n",
       "           [ 4,  4]]])},\n",
       " {'entity_inds': [[(1, 4), (7, 8)],\n",
       "   [(1, 4), (6, 7)],\n",
       "   [(8, 11), (12, 13)],\n",
       "   [(5, 8), (11, 12)],\n",
       "   [(5, 8), (11, 12)],\n",
       "   [(5, 8), (9, 10)],\n",
       "   [(5, 8), (9, 10)],\n",
       "   [(2, 5), (12, 13)]],\n",
       "  'text_lengths': [10, 9, 16, 14, 14, 14, 13, 15],\n",
       "  'entity_lengths': [2, 2, 2, 2, 2, 2, 2, 2],\n",
       "  'text': tensor([[   2, 3926, 3913, 3927,   29,   70,   12, 3927,   14,    3,    0,    0,\n",
       "              0,    0,    0,    0],\n",
       "          [   2, 3926, 3913, 3927,   70,   12, 3927,   14,    3,    0,    0,    0,\n",
       "              0,    0,    0,    0],\n",
       "          [   2,   10,   53,   12,   10,   74,   51,   34, 3926, 3933, 3916,   29,\n",
       "           3934,   76,   14,    3],\n",
       "          [   2,   10,   81,   51,   34, 3926, 3933, 3916,   29,   82,   83, 3935,\n",
       "             14,    3,    0,    0],\n",
       "          [   2,   10,   74,   51,   34, 3926, 3933, 3916,   29,   82,   12, 3935,\n",
       "             14,    3,    0,    0],\n",
       "          [   2,   10,   86,   51,   34, 3926, 3933, 3916,   29, 3936,   76,   87,\n",
       "             14,    3,    0,    0],\n",
       "          [   2,   10,   85,   51,   34, 3926, 3933, 3916,   29, 3936,   76,   14,\n",
       "              3,    0,    0,    0],\n",
       "          [   2,   10, 3926, 3933, 3916,   89,   85,   51,   53,   29,   90,   29,\n",
       "           3936,   14,    3,    0]]),\n",
       "  'labels': tensor([[[ 4, 12],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4, 12],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4, 13],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4, 14],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4, 14],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4,  4],\n",
       "           [15,  4]],\n",
       "  \n",
       "          [[ 4,  4],\n",
       "           [15,  4]],\n",
       "  \n",
       "          [[ 4,  4],\n",
       "           [15,  4]]])},\n",
       " {'entity_inds': [[(1, 4), (8, 11)],\n",
       "   [(1, 4), (10, 13)],\n",
       "   [(6, 9), (10, 13)],\n",
       "   [(1, 4), (12, 13)],\n",
       "   [(2, 5), (6, 7)],\n",
       "   [(1, 4), (6, 7)],\n",
       "   [(5, 8), (9, 12)],\n",
       "   [(2, 5), (10, 13)]],\n",
       "  'text_lengths': [13, 15, 15, 15, 13, 13, 14, 16],\n",
       "  'entity_lengths': [2, 2, 2, 2, 2, 2, 2, 2],\n",
       "  'text': tensor([[   2, 3926, 3933, 3916,   94,   37,   95,   29, 3911, 3937, 3915,   14,\n",
       "              3,    0,    0,    0],\n",
       "          [   2, 3911, 3937, 3915,   29,   10,   94,   37,   95,   12, 3926, 3933,\n",
       "           3916,   14,    3,    0],\n",
       "          [   2,   10,   94,   37,   95,   12, 3926, 3933, 3916,   29, 3911, 3937,\n",
       "           3915,   14,    3,    0],\n",
       "          [   2, 3926, 3933, 3916,   22,   30,   10,   31,   32,   27,   28,   29,\n",
       "           3938,   14,    3,    0],\n",
       "          [   2,   10, 3926, 3933, 3916,   29, 3938,   28,   30,   31,   32,   14,\n",
       "              3,    0,    0,    0],\n",
       "          [   2, 3926, 3933, 3916,   29,   38, 3938,   28,   30,   31,   32,   14,\n",
       "              3,    0,    0,    0],\n",
       "          [   2,   10,   37,   95,   48, 3926, 3933, 3916,   29, 3911, 3939, 3915,\n",
       "             14,    3,    0,    0],\n",
       "          [   2,   10, 3926, 3933, 3916,   89,   37,   99,   29,   15, 3911, 3939,\n",
       "           3915,   15,   14,    3]]),\n",
       "  'labels': tensor([[[ 4, 16],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4, 16],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4, 16],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4,  6],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4,  6],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4,  6],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4,  4],\n",
       "           [17,  4]],\n",
       "  \n",
       "          [[ 4,  4],\n",
       "           [17,  4]]])},\n",
       " {'entity_inds': [[(5, 8), (9, 12)],\n",
       "   [(5, 8), (9, 10)],\n",
       "   [(1, 4), (9, 10)],\n",
       "   [(5, 8), (9, 10)],\n",
       "   [(5, 8), (9, 10)],\n",
       "   [(5, 8), (9, 10)],\n",
       "   [(5, 8), (9, 10)],\n",
       "   [(1, 4), (7, 10)]],\n",
       "  'text_lengths': [14, 12, 12, 12, 12, 12, 12, 12],\n",
       "  'entity_lengths': [2, 2, 2, 2, 2, 2, 2, 2],\n",
       "  'text': tensor([[   2,   10,   37,   95,   12, 3926, 3933, 3916,   29, 3911, 3939, 3915,\n",
       "             14,    3],\n",
       "          [   2,   10,   51,   53,   12, 3926, 3933, 3916,   29, 3940,   14,    3,\n",
       "              0,    0],\n",
       "          [   2, 3926, 3933, 3916,   55,   56,   51,   53,   12, 3940,   14,    3,\n",
       "              0,    0],\n",
       "          [   2,   10,   51,   53,   12, 3926, 3933, 3916,   29, 3940,   14,    3,\n",
       "              0,    0],\n",
       "          [   2,   10,   51,   53,   12, 3926, 3933, 3916,   29, 3941,   14,    3,\n",
       "              0,    0],\n",
       "          [   2,   10,   51,   53,   12, 3926, 3933, 3916,   29, 3942,   14,    3,\n",
       "              0,    0],\n",
       "          [   2,   10,   51,   53,   12, 3926, 3933, 3916,   29, 3942,   14,    3,\n",
       "              0,    0],\n",
       "          [   2, 3926, 3933, 3916,   51,   60,   29, 3911, 3943, 3915,   14,    3,\n",
       "              0,    0]]),\n",
       "  'labels': tensor([[[ 4,  4],\n",
       "           [17,  4]],\n",
       "  \n",
       "          [[ 4,  9],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4,  9],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4,  9],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4,  4],\n",
       "           [ 9,  4]],\n",
       "  \n",
       "          [[ 4,  9],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4,  9],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4, 10],\n",
       "           [ 4,  4]]])},\n",
       " {'entity_inds': [[(1, 4), (9, 12)],\n",
       "   [(1, 4), (8, 11)],\n",
       "   [(1, 4), (9, 12)],\n",
       "   [(7, 10), (11, 14)],\n",
       "   [(5, 8), (9, 12)],\n",
       "   [(8, 11), (12, 13)],\n",
       "   [(1, 2), (11, 14)],\n",
       "   [(8, 11), (12, 13)]],\n",
       "  'text_lengths': [14, 13, 14, 16, 14, 16, 16, 15],\n",
       "  'entity_lengths': [2, 2, 2, 2, 2, 2, 2, 2],\n",
       "  'text': tensor([[   2, 3911, 3943, 3915,   29,   10,   51,   60,   12, 3926, 3933, 3916,\n",
       "             14,    3,    0,    0],\n",
       "          [   2, 3926, 3933, 3916,   55,   10,   51,   60, 3911, 3943, 3915,   14,\n",
       "              3,    0,    0,    0],\n",
       "          [   2, 3911, 3944, 3915,   29,   10,   51,   60,   34, 3926, 3933, 3916,\n",
       "             14,    3,    0,    0],\n",
       "          [   2,   10,   60,   12,   10,   51,   34, 3926, 3933, 3916,   29, 3911,\n",
       "           3944, 3915,   14,    3],\n",
       "          [   2,   10,   51,   60,   12, 3926, 3933, 3916,   29, 3911, 3944, 3915,\n",
       "             14,    3,    0,    0],\n",
       "          [   2,   10,   53,   12,   10,   81,   51,   34, 3946, 3933, 3916,   29,\n",
       "           3945,   76,   14,    3],\n",
       "          [   2, 3945,   76,   29,   10,   53,   12,   10,   81,   51,   34, 3946,\n",
       "           3933, 3916,   14,    3],\n",
       "          [   2,   10,   74,   51,   53,   27,   76,   12, 3946, 3933, 3916,   29,\n",
       "           3945,   14,    3,    0]]),\n",
       "  'labels': tensor([[[ 4, 10],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4, 10],\n",
       "           [ 4,  4]],\n",
       "  \n",
       "          [[ 4,  4],\n",
       "           [10,  4]],\n",
       "  \n",
       "          [[ 4,  4],\n",
       "           [10,  4]],\n",
       "  \n",
       "          [[ 4,  4],\n",
       "           [10,  4]],\n",
       "  \n",
       "          [[ 4,  4],\n",
       "           [13,  4]],\n",
       "  \n",
       "          [[ 4,  4],\n",
       "           [13,  4]],\n",
       "  \n",
       "          [[ 4,  4],\n",
       "           [13,  4]]])}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelLSTM(\n",
       "  (emb): Embedding(6345, 768)\n",
       "  (lstm): LSTM(768, 384, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (relation_layer1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (relation_layer2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       "  (projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (decoder): Linear(in_features=768, out_features=249, bias=True)\n",
       "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2g_model.model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c5ce5b9604fc8445e4e5f27c24807def7cbbefbcd7dbec7e9c2f61ff534743b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
